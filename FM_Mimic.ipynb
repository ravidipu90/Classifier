{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,utils\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torchvision as tv\n",
    "from torch.optim import lr_scheduler\n",
    "from pytorch_msssim import SSIM\n",
    "\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "\n",
    "import shutil \n",
    "import ntpath\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# from sklearn.metrics import precision_score,f1_score,roc_curve,auc,accuracy_score\n",
    "# from models.gaussian_blur import GaussianBlur\n",
    "# from models.gamma_correction import GammaCorrection,HistogramEqualization\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'FM_MIMIC/EXP4'\n",
    "        self.dataset_name = 'MIMIC'\n",
    "        self.dataroot ='../DATASET/MIMIC/IMAGES'\n",
    "        self.save_path = './checkpoint/' + self.name\n",
    "        self.model_path = self.save_path + '/models'\n",
    "        self.decode_path = self.save_path + '/decoded_results'\n",
    "        self.val_path = self.save_path + '/val_results'\n",
    "        self.test_path = self.save_path + '/test_results'\n",
    "        \n",
    "        self.num_threads = 1\n",
    "        self.shuffle_dataset=True\n",
    "        self.random_seed=24\n",
    "\n",
    "\n",
    "        self.lr = 0.0001     \n",
    "        \n",
    "        self.serial_batches = False\n",
    "        self.phase='train'\n",
    "        \n",
    "        self.batch_size = 1\n",
    "        self.test_batch_size = 1\n",
    "        self.c_batch_size = 1\n",
    "        self.max_epochs = 500\n",
    "        self.save_every = 1     #epoch\n",
    "        self.plot_every = 1    # epoch to save decoded images\n",
    "\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "        os.makedirs(self.model_path, exist_ok=True)\n",
    "        os.makedirs(self.decode_path, exist_ok=True)\n",
    "        os.makedirs(self.val_path, exist_ok=True)\n",
    "        os.makedirs(self.test_path, exist_ok=True)\n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path= '../DATASET/MIMIC/test.csv'\n",
    "# df = pd.read_csv(path)\n",
    "# df = df.sample(frac = 1) \n",
    "# df.to_csv('../DATASET/MIMIC/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17909, 5) (5371, 5) (3586, 5) (392, 5)\n"
     ]
    }
   ],
   "source": [
    "phases = ['train', 'val','test','covid'] \n",
    "root_dir = '../DATASET/MIMIC/'\n",
    "data_dir ='../DATASET/MIMIC/IMAGES'\n",
    "# Path to csvfiles on training,validation and tetsing data\n",
    "csvpath = {phase: f'{root_dir}/{phase}.csv' for phase in phases}\n",
    "# Load data into dictionary of three Pandas DataFrames\n",
    "dframe = {phase: pd.read_csv(csvpath[phase]) for phase in phases}\n",
    "# Calculate sizes\n",
    "dataset_sizes = {phase: len(dframe[phase]) for phase in phases}\n",
    "print(dframe['train'].shape, dframe['val'].shape,dframe['test'].shape,dframe['covid'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['c', 'o', 'e', 'n'], dtype='object')\n",
      "torch.Size([17909, 4])\n",
      "torch.Size([5371, 4])\n",
      "torch.Size([3586, 4])\n",
      "torch.Size([392, 4])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "class_names = dframe['train'].iloc[:, 1:].columns\n",
    "print(class_names)\n",
    "# indices we will calculate AUC for, \n",
    "competition_tasks = torch.ByteTensor([1,1,1,1]).bool()\n",
    "\n",
    "df = dframe['train'].iloc[:, 1:].copy()\n",
    "labels_array = df.iloc[:, 1:].copy()\n",
    "labels_array = {phase: dframe[phase].iloc[:, 1:].copy() for phase in phases}\n",
    "\n",
    "for phase in labels_array.keys():\n",
    "    labels_array[phase] = torch.FloatTensor(labels_array[phase].to_numpy())\n",
    "#     labels_array[phase] = torch.LongTensor(labels_array[phase].to_numpy())\n",
    "\n",
    "\n",
    "print(labels_array['train'].shape)\n",
    "print(labels_array['val'].shape)\n",
    "print(labels_array['test'].shape)\n",
    "print(labels_array['covid'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array['covid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [ 'Consolidation', 'Opacity','Effusion', 'No_Findings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([#transforms.Grayscale(num_output_channels=1),\n",
    "                              transforms.Resize(256),\n",
    "                              transforms.CenterCrop(224),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.ToTensor(),\n",
    "#                               transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "                            ])\n",
    "\n",
    "# normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                                      [0.229, 0.224, 0.225])\n",
    "# transform=transforms.Compose([#transforms.Grayscale(num_output_channels=1),\n",
    "#                               transforms.Resize(256),\n",
    "#                               transforms.FiveCrop(224),\n",
    "#                               transforms.Lambda\n",
    "#                                 (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "#                               transforms.Lambda\n",
    "#                                 (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "#                             ])\n",
    "           \n",
    "\n",
    "class Data(data.Dataset):\n",
    "    def __init__(self,img_paths, labels_array ,phase=None, tforms=None):\n",
    "        self.transform=transform\n",
    "        self.phase = phase\n",
    "        self.img_paths = img_paths\n",
    "        self.labels_array = labels_array \n",
    "                    \n",
    "    def __len__(self):\n",
    "            return len(self.img_paths)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        file = self.img_paths[index]\n",
    "        image = Image.open(file).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels_array[index]\n",
    "#         label = torch.FloatTensor([label])\n",
    "#         label = torch.LongTensor([label])\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = {phase: data_dir +'/'+ dframe[phase].iloc[:, 0] for phase in phases}\n",
    "datasets = {phase: Data(img_paths=img_paths[phase],labels_array=labels_array[phase],phase=phase,tforms=transform) \n",
    "            for phase in phases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17909 images loaded under train\n",
      "5371 images loaded under val\n",
      "3586 images loaded under test\n",
      "392 images loaded under covid\n"
     ]
    }
   ],
   "source": [
    "num_workers = 8\n",
    "params = {'train': {'batch_size': opt.batch_size,\n",
    "                    'shuffle': True,\n",
    "                    'num_workers': num_workers,\n",
    "                    'pin_memory': True,\n",
    "                    'sampler': None,\n",
    "                    'drop_last':True},\n",
    "          'val': {'batch_size': opt.batch_size,\n",
    "                  'shuffle': True,\n",
    "                  'num_workers': num_workers,\n",
    "                  'pin_memory': True,\n",
    "                   'drop_last':True},\n",
    "           'test': {'batch_size': opt.test_batch_size,\n",
    "                  'shuffle': True,\n",
    "                  'num_workers': num_workers,\n",
    "                  'pin_memory': True,\n",
    "                   'drop_last':True},\n",
    "            'covid': {'batch_size': opt.c_batch_size,\n",
    "                  'shuffle': True,\n",
    "                  'num_workers': num_workers,\n",
    "                  'pin_memory': True,\n",
    "                   'drop_last':True}\n",
    "         }\n",
    "\n",
    "if params['train']['sampler'] is not None:\n",
    "    params['train']['shuffle'] = False\n",
    "    \n",
    "dataloaders = {phase: data.DataLoader(datasets[phase], **params[phase]) for phase in phases}\n",
    "for phase in phases:\n",
    "    print(f'{len(datasets[phase])} images loaded under {phase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(dataloaders['test'])\n",
    "# images, labels = dataiter.next()\n",
    "# # grid_img = torchvision.utils.make_grid(images, nrow=1)\n",
    "# plt.imshow(images.permute(1, 2, 0))\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=models.densenet169(pretrained=True)\n",
    "# num_ftrs = model.classifier.in_features\n",
    "# model.classifier= nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    \"\"\"Model modified.\n",
    "    The architecture of our model is the same as standard DenseNet121\n",
    "    except the classifier layer which has an additional sigmoid function.\n",
    "    \"\"\"\n",
    "    def __init__(self, out_size):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = models.densenet121(pretrained=True)\n",
    "        num_ftrs = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model = torch.nn.Sequential(*(list(model.children())[:-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(dataloaders['train'])\n",
    "# images, labels = dataiter.next()\n",
    "# out = cls(images)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNet121(4)\n",
    "state = torch.load(os.path.join(opt.model_path,'chexnet2.pth'),map_location='cuda:6')\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    TPRs = FPRs = THs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(num_classes):\n",
    "        try:\n",
    "            AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "            fpr, tpr, thresholds = roc_curve(gt_np[:, i], pred_np[:, i])\n",
    "            TPRs.append(tpr)\n",
    "            FPRs.append(fpr)\n",
    "            THs.append(thresholds)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return AUROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_pooling():\n",
    "    return nn.MaxPool2d(2)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_z=512      # number of dimensions in latent space.\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(64),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv11 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(64),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        \n",
    "        self.conv2=nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(128),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv22=nn.Sequential(nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(128),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv3=nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(256),\n",
    "                                 nn.LeakyReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv33=nn.Sequential(nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(256),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv4=nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(512),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv44=nn.Sequential(nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(512),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )        \n",
    "        self.conv5=nn.Sequential(nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(1024),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv55=nn.Sequential(nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(1024),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.down_pooling = nn.MaxPool2d(2)\n",
    "        \n",
    "#         self.mu = nn.Linear(1024*14*14, 512)\n",
    "#         self.logvar = nn.Linear(1024*14*14, 512)\n",
    "        self.mu = nn.Sequential( nn.Linear((1024*14*14), 512),\n",
    "                                 nn.BatchNorm1d(512),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(512,512))\n",
    "        self.logvar = nn.Sequential( nn.Linear((1024*14*14),512),\n",
    "                                 nn.BatchNorm1d(512),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(512,512))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "        return sample\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=self.conv1(x)\n",
    "        x=self.conv11(x)\n",
    "        x = self.down_pooling(x)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x=self.conv22(x)\n",
    "        x = self.down_pooling(x)\n",
    "        \n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.conv33(x)\n",
    "        x = self.down_pooling(x)\n",
    "\n",
    "        \n",
    "        x=self.conv4(x)\n",
    "        x=self.conv44(x)\n",
    "        x = self.down_pooling(x)\n",
    "        \n",
    "        x=self.conv5(x)\n",
    "        x=self.conv55(x)\n",
    "#         print(x.size())\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        mu, logvar = self.mu(x), self.logvar(x)\n",
    "        x = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        return x,mu,logvar\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def up_pooling(in_channels, out_channels, kernel_size=2, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "def conv_bn_leru(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "#         self.fc = nn.Sequential(nn.Linear(512,1024*14*14),\n",
    "#                                 nn.ReLU()\n",
    "#                                 )\n",
    "        self.fc = nn.Sequential( nn.Linear(512, 512),\n",
    "                                 nn.BatchNorm1d(512),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(512,1024*14*14))\n",
    "    \n",
    "        self.up_pool6 = up_pooling(1024, 1024)\n",
    "        self.conv6 = conv_bn_leru(1024, 512)\n",
    "        self.up_pool7 = up_pooling(512, 512)\n",
    "        self.conv7 = conv_bn_leru(512, 256)\n",
    "        self.up_pool8 = up_pooling(256, 256)\n",
    "        self.conv8 = conv_bn_leru(256, 128)\n",
    "        self.up_pool9 = up_pooling(128, 128)\n",
    "        self.conv9 = conv_bn_leru(128, 64)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(64, 3,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x  = self.fc(x)\n",
    "        x5 = x.view(x.size(0),1024,14,14)\n",
    "        \n",
    "        p6 = self.up_pool6(x5)\n",
    "        x6 = self.conv6(p6)\n",
    "\n",
    "        p7 = self.up_pool7(x6)\n",
    "        x7 = self.conv7(p7)\n",
    "\n",
    "        p8 = self.up_pool8(x7)\n",
    "        x8 = self.conv8(p8)\n",
    "\n",
    "        p9 = self.up_pool9(x8)\n",
    "        x9 = self.conv9(p9)\n",
    "        \n",
    "        output = self.conv10(x9)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "encoder=Encoder()\n",
    "encoder.apply(weight_init)\n",
    "decoder=Decoder()\n",
    "decoder.apply(weight_init)\n",
    "encoder, decoder= encoder.to(device), decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSIM_Loss(SSIM):\n",
    "    def forward(self, img1, img2):\n",
    "        return ( 1 - super(SSIM_Loss, self).forward(img1, img2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "def frozen_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_params(encoder)\n",
    "frozen_params(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained model with success.\n",
      "Previously Trained for 197 epoches\n",
      "Best val AUC till yet : 0.8380716209476995\n"
     ]
    }
   ],
   "source": [
    "state = torch.load(os.path.join(opt.model_path,'model2.pth'),map_location='cuda:6')\n",
    "model.load_state_dict(state['state_dict'])\n",
    "print(\"Loaded pre-trained model with success.\")\n",
    "e_counter=state['epoch']\n",
    "best_auc = state['valid_acc_max']\n",
    "print('Previously Trained for {} epoches'.format(e_counter))\n",
    "print('Best val AUC till yet :',best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained models with success.\n",
      "Previously Trained for 866 epoches\n"
     ]
    }
   ],
   "source": [
    "state = torch.load(os.path.join(opt.model_path, 'vae.pth'),map_location='cuda:6')\n",
    "encoder.load_state_dict(state['enc_state_dict'])\n",
    "decoder.load_state_dict(state['dec_state_dict'])\n",
    "print(\"Loaded pre-trained models with success.\")\n",
    "e_counter=state['epoch']\n",
    "best_valid_loss = state['loss_min']\n",
    "print('Previously Trained for {} epoches'.format(e_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MainNet(**kwargs):\n",
    "    torch.cuda.empty_cache()\n",
    "    opt = Config()\n",
    "    print('loading the model...') \n",
    "#     criterion = nn.BCEWithLogitsLoss(reduction='sum').to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    l1_loss = nn.L1Loss()\n",
    "\n",
    "    \n",
    "    model.to(device)\n",
    "    l=10\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = opt.lr,weight_decay=4e-3)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=opt.max_epochs, eta_min=0.000001)\n",
    "\n",
    "    try:\n",
    "        state = torch.load(os.path.join(opt.model_path,'I_model.pth'),map_location='cuda:6')\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        print(\"Loaded pre-trained model with success.\")\n",
    "        e_counter=state['epoch']\n",
    "        best_auc = state['valid_acc_max']\n",
    "        print('Previously Trained for {} epoches'.format(e_counter))\n",
    "        print('Best val AUC till yet :',best_auc)\n",
    "        e_counter+=1\n",
    "    except FileNotFoundError:\n",
    "        print(\"Pre-trained weights not found. Training from scratch.\")\n",
    "        e_counter=0\n",
    "        best_valid_loss = float('inf')\n",
    "        best_auc = 0.0\n",
    "        \n",
    "    lrs = []\n",
    "    t_loss = []\n",
    "    t_auc = []\n",
    "    v_loss=[]\n",
    "    v_auc=[]\n",
    "    epoches=[]\n",
    "    \n",
    "    for epoch in range(e_counter,opt.max_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print()\n",
    "        print('==================================================================')\n",
    "        print('-------------Epoch: {}/{}------------'.format(epoch,opt.max_epochs))\n",
    "        phase = 'train'\n",
    "        running_loss=0.0\n",
    "        train_auc=0.0\n",
    "    \n",
    "        model.train()\n",
    "        for idx,batch in enumerate(dataloaders[phase],1):\n",
    "            images,labels=batch\n",
    "            images,labels=images.to(device),labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            enc_out,mu,logvar = encoder(images)\n",
    "            dec_out = decoder(enc_out)    \n",
    "            \n",
    "            outputs = model(dec_out)\n",
    "            loss = l*criterion(outputs, labels)+l*l1_loss (labels,outputs)\n",
    "\n",
    "\n",
    "#             bs, n_crops, c, h, w = images.size()\n",
    "#             inputs = images.view(-1, c, h, w)\n",
    "#             inputs = torch.autograd.Variable(inputs.view(-1, c, h, w))\n",
    "#             target = torch.autograd.Variable(labels)\n",
    "#             outputs = model(inputs).view(bs, n_crops, -1).mean(dim=1)\n",
    "#             loss = l*criterion(outputs, target)+l*l1_loss (target,outputs)\n",
    "\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "            \n",
    "            preds = outputs.data > 0.5                \n",
    "            preds = preds.to(torch.float32)\n",
    "            AUROCs = compute_AUCs(labels, preds)\n",
    "            AUROC_avg = np.array(AUROCs).mean()\n",
    "            train_auc += AUROC_avg\n",
    "            \n",
    "            \n",
    "            if (idx)%200 == 0:  \n",
    "                print(f'{phase}_batch {idx+1}/{len(dataloaders[phase])} Loss: {(running_loss/(idx)):.5f}'\n",
    "                          f' AUC: {(train_auc /(idx)):.3f}'\n",
    "                     )\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase])                       \n",
    "        epoch_auc = train_auc/ len(dataloaders[phase])\n",
    "        t_auc.append(epoch_auc)\n",
    "        t_loss.append(epoch_loss)\n",
    "        print(f'{phase} Epoch Loss: {epoch_loss:.5f} AUC: {epoch_auc: .3f}')\n",
    "    \n",
    "        with open(f'{opt.save_path}/train_logs.txt', 'a') as file:\n",
    "            file.write('epoch: ' + str(epoch) + ',loss: '+ str(epoch_loss) + ',auc: ' + str(epoch_auc) +'\\n')\n",
    "\n",
    "        print('.............')\n",
    "        phase = 'val'\n",
    "\n",
    "        running_loss=0.0\n",
    "        val_auc=0.0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx,batch in enumerate(dataloaders[phase],1):\n",
    "                images,labels=batch\n",
    "                images,labels=images.to(device),labels.to(device)\n",
    "                \n",
    "                 \n",
    "                enc_out,mu,logvar = encoder(images)\n",
    "                dec_out = decoder(enc_out)    \n",
    "\n",
    "                outputs = model(dec_out)\n",
    "\n",
    "                loss = l*criterion(outputs, labels)+l*l1_loss (labels,outputs)\n",
    "#                 bs, n_crops, c, h, w = images.size()\n",
    "#                 inputs = images.view(-1, c, h, w)\n",
    "#                 inputs = torch.autograd.Variable(inputs.view(-1, c, h, w))\n",
    "#                 target = torch.autograd.Variable(labels)\n",
    "#                 outputs = model(inputs).view(bs, n_crops, -1).mean(dim=1)\n",
    "#                 loss = l*criterion(outputs, target)+l*l1_loss (target,outputs)\n",
    "\n",
    "\n",
    "                preds = outputs.data > 0.5               \n",
    "                preds = preds.to(torch.float32)\n",
    "\n",
    "                running_loss += loss.item() \n",
    "                AUROCs = compute_AUCs(labels, preds)\n",
    "                AUROC_avg = np.array(AUROCs).mean()\n",
    "                val_auc += AUROC_avg\n",
    "\n",
    "                if (idx)%100 == 0:  \n",
    "                    print(f'{phase}_batch {idx}/{len(dataloaders[phase])} Loss: {(running_loss/((idx))):.5f}'\n",
    "                              f' AUC: {(val_auc /((idx))):.3f}'\n",
    "                         )\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase])                        \n",
    "        epoch_auc = val_auc/ len(dataloaders[phase])\n",
    "        v_auc.append(epoch_auc)\n",
    "        v_loss.append(epoch_loss)\n",
    "        epoches.append(epoch)\n",
    "        print(f'{phase} Epoch Loss: {epoch_loss:.5f} AUC: {epoch_auc: .3f}')\n",
    "\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'valid_acc_max': epoch_auc,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "\n",
    "        if epoch_auc > best_auc:\n",
    "            print('Val auc increased ({:.3f} --> {:.3f}). Saving model ...'.format(best_auc,epoch_auc))\n",
    "            torch.save(state, os.path.join(opt.model_path, 'I_model.pth'))\n",
    "            with open(f'{opt.save_path}/val_logs.txt', 'a') as file:\n",
    "                file.write('epoch: ' + str(epoch) + ',loss: ' + str(epoch_loss)+',auc: ' + str(epoch_auc) +'\\n')\n",
    "            best_auc = epoch_auc\n",
    "            epoch_time = int(time.time() - epoch_start_time)\n",
    "            print(f'-----------------Epoch cost time {epoch_time}s--------------------')\n",
    "        \n",
    "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        print('learning_rate :',scheduler.get_lr())\n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "    plt.plot(lrs)\n",
    "    \n",
    "    filepath=os.path.join(opt.save_path, 'LR.png')\n",
    "    plt.savefig(filepath)\n",
    "    \n",
    "    filepath=os.path.join(opt.save_path, 'losses.png')\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(epoches, t_loss, label=\"Train\")\n",
    "    plt.plot(epoches, v_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(filepath)\n",
    "    \n",
    "    filepath=os.path.join(opt.save_path, 'classifier_accuracy.png')\n",
    "    plt.title(\"AUC Curve\")\n",
    "    plt.plot(epoches, t_auc, label=\"Train\")\n",
    "    plt.plot(epoches, v_auc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"ACC\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_MainNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TAUCs(gt, pred):\n",
    "    AUROCs = []\n",
    "    TPRs = FPRs = THs = []\n",
    "    gt_np = gt\n",
    "    pred_np = pred\n",
    "    for i in range(num_classes):\n",
    "        try:\n",
    "            AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return AUROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(phase):\n",
    "    torch.cuda.empty_cache()\n",
    "    opt = Config()\n",
    "    model.to(device)\n",
    "    P=[]\n",
    "    L=[]\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloaders[phase]):\n",
    "        images,labels=batch\n",
    "        images,labels=images.to(device),labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.data > 0.5               \n",
    "        preds = preds.to(torch.float32)\n",
    "\n",
    "        preds=preds.cpu().numpy().flatten()\n",
    "        labels=labels.cpu().numpy().flatten()\n",
    "\n",
    "        P.append(preds)\n",
    "        L.append(labels)\n",
    "        \n",
    "    P = np.array(P)\n",
    "    L = np.array(L)\n",
    "    AUROCs = compute_TAUCs(L,P)\n",
    "    AUROC_avg = np.array(AUROCs).mean()\n",
    "    print(f'AUC on {phase} set: ',AUROC_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5371/5371 [02:37<00:00, 34.04it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on val set:  0.5043762591195272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 392/392 [00:17<00:00, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on covid set:  0.5255940295223491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "phase = ['val','covid']\n",
    "# phase=['covid']\n",
    "for p in phase:\n",
    "    test(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_np =np.array([[1,1,0,1], [1, 1, 0,0], [0, 0 ,0,1]])\n",
    "# pred_np =np.array([[1,1,0,1], [1, 1, 0,0], [0, 0 ,0,1]])\n",
    "# AUROCs = []\n",
    "# for i in range(4):\n",
    "#     try:\n",
    "#         AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "#     except:\n",
    "#         pass\n",
    "# print(AUROCs)\n",
    "# AUROC_avg = np.array(AUROCs).mean()\n",
    "# print(AUROC_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
